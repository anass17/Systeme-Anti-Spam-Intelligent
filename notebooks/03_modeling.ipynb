{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9210709a",
   "metadata": {},
   "source": [
    "### Chargement de donnÃ©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "199b303e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/processed/data_stemmed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a15e368",
   "metadata": {},
   "source": [
    "### 1. Vectoriser le texte Ã  lâ€™aide de TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e48e44b",
   "metadata": {},
   "source": [
    "- Label et label_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1615874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>label_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label label_text\n",
       "0      1       spam\n",
       "1      0        ham"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"label\", \"label_text\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab8f716",
   "metadata": {},
   "source": [
    "- SÃ©parer features et labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c48cfd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"label\"]\n",
    "X = df[\"stemmed_text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24267d56",
   "metadata": {},
   "source": [
    "- Split train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec2af02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X - Train 23040\n",
      "X - Test 5761\n",
      "y - Train 23040\n",
      "y - Test 5761\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"X - Train\", len(X_train_text))\n",
    "print(\"X - Test\", len(X_test_text))\n",
    "print(\"y - Train\", len(y_train))\n",
    "print(\"y - Test\", len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cd818d",
   "metadata": {},
   "source": [
    "- Vectorisation du texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a9ed8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23040, 8000) (5761, 8000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=8000)\n",
    "X_train = vectorizer.fit_transform(X_train_text)\n",
    "X_test = vectorizer.transform(X_test_text)\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c096ece5",
   "metadata": {},
   "source": [
    "### 2. EntraÃ®ner plusieurs modÃ¨les de classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51f60b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Training Logistic Regression...\n",
      "ðŸ”¹ Training Linear SVM...\n",
      "ðŸ”¹ Training Naive Bayes...\n",
      "ðŸ”¹ Training Random Forest...\n",
      "ðŸ”¹ Training SGDClassifier (SVM-like)...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# ModÃ¨les\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# 3. Liste des modÃ¨les Ã  tester\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=300),\n",
    "    \"Linear SVM\": LinearSVC(),\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=200),\n",
    "    \"SGDClassifier\": SGDClassifier(loss=\"hinge\"),\n",
    "}\n",
    "\n",
    "# 4. Stocker les rÃ©sultats\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"ðŸ”¹ Training {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    precision = precision_score(y_test, preds, pos_label=1)\n",
    "    recall = recall_score(y_test, preds, pos_label=1)\n",
    "    f1 = f1_score(y_test, preds, pos_label=1)\n",
    "\n",
    "    results.append([name, accuracy, precision, recall, f1])\n",
    "\n",
    "# 5. Afficher les rÃ©sultats\n",
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2c3eaf13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.985072</td>\n",
       "      <td>0.976915</td>\n",
       "      <td>0.991447</td>\n",
       "      <td>0.984127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>0.988196</td>\n",
       "      <td>0.984832</td>\n",
       "      <td>0.989959</td>\n",
       "      <td>0.987389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.981427</td>\n",
       "      <td>0.976032</td>\n",
       "      <td>0.984381</td>\n",
       "      <td>0.980189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.984378</td>\n",
       "      <td>0.977933</td>\n",
       "      <td>0.988843</td>\n",
       "      <td>0.983358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.988544</td>\n",
       "      <td>0.983413</td>\n",
       "      <td>0.992190</td>\n",
       "      <td>0.987782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1-score\n",
       "0  Logistic Regression  0.985072   0.976915  0.991447  0.984127\n",
       "1           Linear SVM  0.988196   0.984832  0.989959  0.987389\n",
       "2          Naive Bayes  0.981427   0.976032  0.984381  0.980189\n",
       "3        Random Forest  0.984378   0.977933  0.988843  0.983358\n",
       "4        SGDClassifier  0.988544   0.983413  0.992190  0.987782"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606b5380",
   "metadata": {},
   "source": [
    "SGDClassifier est le modÃ©le le plus performant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16740a1",
   "metadata": {},
   "source": [
    "### 3. Optimiser les modÃ¨les (GridSearch)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fce907",
   "metadata": {},
   "source": [
    "- Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f6bcd2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 30, 'max_iter': 40}\n",
      "0.9881564982517437\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "params_lr = {\n",
    "    \"C\": [5, 10, 15, 20, 30, 40, 50],\n",
    "    \"max_iter\": [40, 50, 70, 100]\n",
    "}\n",
    "\n",
    "grid_lr = GridSearchCV(LogisticRegression(), params_lr, cv=5, scoring=\"f1\")\n",
    "grid_lr.fit(X_train, y_train)\n",
    "\n",
    "print(grid_lr.best_params_)\n",
    "print(grid_lr.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ce2801",
   "metadata": {},
   "source": [
    "- Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b86a5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anass\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\anass\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\anass\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\anass\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\anass\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\anass\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\anass\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.5, 'loss': 'squared_hinge', 'max_iter': 2000}\n",
      "0.9884114583333332\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "params_svm = {\n",
    "    \"C\": [0.01, 0.1, 0.5, 1, 2, 3, 5],\n",
    "    \"loss\": [\"hinge\", \"squared_hinge\"],\n",
    "    \"max_iter\": [2000, 3000, 5000]\n",
    "}\n",
    "\n",
    "grid_svm = GridSearchCV(LinearSVC(), params_svm, cv=5, scoring=\"accuracy\")\n",
    "grid_svm.fit(X_train, y_train)\n",
    "\n",
    "print(grid_svm.best_params_)\n",
    "print(grid_svm.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ce7973",
   "metadata": {},
   "source": [
    "- Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "62815dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.1}\n",
      "0.9824198952223366\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "params_nb = {\n",
    "    \"alpha\": [0.1, 0.5, 1.0, 2.0, 5.0]\n",
    "}\n",
    "\n",
    "grid_nb = GridSearchCV(MultinomialNB(), params_nb, cv=5, scoring=\"f1\")\n",
    "grid_nb.fit(X_train, y_train)\n",
    "\n",
    "print(grid_nb.best_params_)\n",
    "print(grid_nb.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04249eb",
   "metadata": {},
   "source": [
    "- Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2981c04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params_rf = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"max_depth\": [None, 10, 20, 40],\n",
    "    \"max_features\": [\"sqrt\", \"log2\"],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "}\n",
    "\n",
    "rnd_rf = GridSearchCV(\n",
    "    RandomForestClassifier(),\n",
    "    params_rf,\n",
    "    cv=2,\n",
    "    scoring=\"f1\")\n",
    "\n",
    "rnd_rf.fit(X_train, y_train)\n",
    "\n",
    "print(rnd_rf.best_params_)\n",
    "print(rnd_rf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe855d1b",
   "metadata": {},
   "source": [
    "- SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a5e00c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 3000, 'penalty': 'l2'}\n",
      "0.9880216474178318\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "params_sgd = {\n",
    "    \"loss\": [\"hinge\", \"log_loss\", \"modified_huber\"],\n",
    "    \"alpha\": [1e-4, 1e-3, 1e-2],\n",
    "    \"penalty\": [\"l2\", \"l1\", \"elasticnet\"],\n",
    "    \"max_iter\": [2000, 3000, 4000, 5000]\n",
    "}\n",
    "\n",
    "grid_sgd = GridSearchCV(\n",
    "    SGDClassifier(),\n",
    "    params_sgd,\n",
    "    cv=5,\n",
    "    scoring=\"f1\"\n",
    ")\n",
    "\n",
    "grid_sgd.fit(X_train, y_train)\n",
    "\n",
    "print(grid_sgd.best_params_)\n",
    "print(grid_sgd.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1ce4936d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Model   Best F1  Best Accuracy\n",
      "0  LogReg  0.988156       0.988196\n",
      "1     SVM  0.988411       0.988370\n",
      "2      NB  0.982420       0.981774\n",
      "3     SGD  0.988022       0.988891\n"
     ]
    }
   ],
   "source": [
    "preds = grid_lr.best_estimator_.predict(X_test)\n",
    "accuracy_lr = accuracy_score(y_test, preds)\n",
    "preds = grid_svm.best_estimator_.predict(X_test)\n",
    "accuracy_svm = accuracy_score(y_test, preds)\n",
    "preds = grid_nb.best_estimator_.predict(X_test)\n",
    "accuracy_nb = accuracy_score(y_test, preds)\n",
    "preds = grid_sgd.best_estimator_.predict(X_test)\n",
    "accuracy_sgd = accuracy_score(y_test, preds)\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    \"Model\": [\"LogReg\", \"SVM\", \"NB\", \"SGD\"],\n",
    "    \"Best F1\": [\n",
    "        grid_lr.best_score_,\n",
    "        grid_svm.best_score_,\n",
    "        grid_nb.best_score_,\n",
    "        grid_sgd.best_score_,\n",
    "    ],\n",
    "    \"Best Accuracy\": [\n",
    "        accuracy_lr,\n",
    "        accuracy_svm,\n",
    "        accuracy_nb,\n",
    "        accuracy_sgd,\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c61548",
   "metadata": {},
   "source": [
    "D'aprÃ©s les resultats de cross validation, on constate que SVM est le modÃ©le le plus performant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95653a20",
   "metadata": {},
   "source": [
    "### 5. Sauvegarder le modÃ¨le final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "91dfc579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Sauvegarde du modÃ¨le final\n",
    "joblib.dump(grid_svm.best_estimator_, \"../models/spam_classifier_model.pkl\")\n",
    "\n",
    "# Sauvegarde du TF-IDF vectorizer\n",
    "joblib.dump(vectorizer, \"../models/tfidf_vectorizer.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
